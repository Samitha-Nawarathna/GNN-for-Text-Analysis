{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNPef4/RSjqpYQM7i8OfuCG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samitha-Nawarathna/GNN-for-Text-Analysis/blob/main/Model_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G3TYiFNCYtS",
        "outputId": "e7ff4c39-0a23-432d-ed81-f1a64e34468b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef0M9PKPDLHY",
        "outputId": "a5d86954-586c-4233-e007-b4db54b78522"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VpOuL2LHCNYm"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/drive/MyDrive/Datasets/bbc-full-text-document-classification/processed/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as gnn\n",
        "from torch_geometric.nn import aggr\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import glob\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JdIclD5tC7AR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SIZE = 50\n",
        "OUTPUT_SIZE = 5\n",
        "EPOCHS = 2"
      ],
      "metadata": {
        "id": "sDhf9Uej0eQx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'"
      ],
      "metadata": {
        "id": "N2NAED0E5ukK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Au-tmf186jZp",
        "outputId": "a7850018-b2a3-4fb0-9594-da8ccf24d286"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Graph_Dataset(Dataset):\n",
        "  def __init__(self,path):\n",
        "    super().__init__()\n",
        "    self.path = path\n",
        "    self.path_list = self.getPaths()\n",
        "\n",
        "  def getPaths(self):\n",
        "    return glob.glob(self.path+'/*/*.pt')\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.path_list)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    #print(idx)\n",
        "    if type(idx) == slice:\n",
        "      graphs = []\n",
        "      start ,step, stop = idx.start, idx.step, idx.stop\n",
        "      if start == None:\n",
        "        start =0\n",
        "      if stop == None:\n",
        "        stop = len(self.path_list)-1\n",
        "      if step == None:\n",
        "        step =1\n",
        "      #print(type(stop))\n",
        "      for item in range(start, stop, step):\n",
        "        graphs.append(torch.load(self.path_list[item]))\n",
        "      return graphs\n",
        "    return torch.load(self.path_list[idx])"
      ],
      "metadata": {
        "id": "4Jnu6kNwC8i_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Graph_Dataset(data_path)"
      ],
      "metadata": {
        "id": "l6O3AdusDEUY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8*len(dataset))\n",
        "test_size = int(0.1*len(dataset))\n",
        "val_size = len(dataset) - train_size - test_size\n",
        "train_set, test_set, val_set = random_split(dataset, [train_size, test_size, val_size])"
      ],
      "metadata": {
        "id": "AMCDDkaj6nQw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.p1 = nn.Linear(input_size, 100)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.p2 = nn.Linear(100,50)\n",
        "    self.p3 = nn.Linear(50,output_size)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.p1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.p2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.p3(x)\n",
        "    return x\n",
        "\n",
        "class GraphModel(nn.Module):\n",
        "  def __init__(self,input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.gconv1 = gnn.conv.GatedGraphConv(out_channels=50, num_layers=50)\n",
        "    self.f1 = MLP(input_size,output_size)\n",
        "    self.f2 = MLP(input_size,output_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.tanh = nn.Tanh()\n",
        "\n",
        "  def forward(self,x,edge_index,edge_attr):\n",
        "    x = self.gconv1(x, edge_index, edge_weight = edge_attr)\n",
        "    #print(x)\n",
        "    x1 = self.f1(x)\n",
        "    #print(x)\n",
        "    x2 = self.f2(x)\n",
        "    #print(x)\n",
        "    x = x1*x2\n",
        "    #print(x)\n",
        "    xg = (1/x.shape[0])*torch.sum(x,dim=0) + torch.max(x, dim=0).values\n",
        "    #print(x)\n",
        "    return xg\n",
        "    #x = self.attention(x)\n"
      ],
      "metadata": {
        "id": "1T6sCtyeIxcy"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphModel(INPUT_SIZE, OUTPUT_SIZE).to(device)"
      ],
      "metadata": {
        "id": "3iuvCiaR0yZb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extractGraph(graph):\n",
        "   x = graph.x.type(torch.float)\n",
        "   edge_index = graph.edge_index.type(torch.int64)\n",
        "   edge_attr = graph.edge_attr.type(torch.float)\n",
        "   return x, edge_index, edge_attr"
      ],
      "metadata": {
        "id": "Cf25w1TCi5EC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPrediction(graph, model):\n",
        "  x, edge_index, edge_attr = extractGraph(graph)\n",
        "  return model(x, edge_index, edge_attr)"
      ],
      "metadata": {
        "id": "Nm8ecLSSjIwQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = dataset[5]"
      ],
      "metadata": {
        "id": "hnPEu3Gqd9EF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "optimizer = Adam(model.parameters(),lr=lr,betas=[0.99,0.95])\n",
        "scheduler = StepLR(optimizer, step_size=500, gamma=0.5)"
      ],
      "metadata": {
        "id": "Oq41p0yl2N9s"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getValErrors(graph, model=model):\n",
        "  graph.to(device)\n",
        "  output = getPrediction(graph,model)\n",
        "  return error(output, graph.y)\n",
        "\n"
      ],
      "metadata": {
        "id": "X24Mfm0r5N3i"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_split,_ = random_split(val_set, [50, len(val_set) - 50])"
      ],
      "metadata": {
        "id": "Uwii6D38TtZ2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = float(\"inf\")"
      ],
      "metadata": {
        "id": "iI5HjQwTXAX_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  for i, graph in enumerate(train_set):\n",
        "    graph.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = getPrediction(graph, model)\n",
        "    y = graph.y.to(device)\n",
        "    loss = error(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    if i%25==0 and i != 0:\n",
        "      val_loss = 0\n",
        "      for item in val_split:\n",
        "        val_loss += getValErrors(item)\n",
        "      val_loss /= len(val_split)\n",
        "      if val_loss < best_loss:\n",
        "        checkpoint_saver = torch.save(model.state_dict(), '/content/drive/MyDrive/Datasets/bbc-full-text-document-classification/models/cheackpoints.pt')\n",
        "        best_loss =val_loss\n",
        "      print(epoch,i,val_loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "unx9Kf6n3i-V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1dfce9d0-08ad-4281-9ca0-9f2ea454bb98"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 25 tensor(1.6096, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 50 tensor(1.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 75 tensor(1.6090, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 100 tensor(1.6090, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 125 tensor(1.6091, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 150 tensor(1.6087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 175 tensor(1.6083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 200 tensor(1.6075, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 225 tensor(1.6062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 250 tensor(1.6052, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 275 tensor(1.6049, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 300 tensor(1.6034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 325 tensor(1.6018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 350 tensor(1.6014, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 375 tensor(1.5991, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 400 tensor(1.5981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 425 tensor(1.6016, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 450 tensor(1.6041, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 475 tensor(1.6087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 500 tensor(1.6137, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 525 tensor(1.6160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 550 tensor(1.6374, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 575 tensor(1.7021, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 600 tensor(1.6292, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 625 tensor(1.6146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 650 tensor(1.6066, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 675 tensor(1.6066, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 700 tensor(1.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 725 tensor(1.6042, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 750 tensor(1.5999, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 775 tensor(1.6008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 800 tensor(1.6005, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 825 tensor(1.6290, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 850 tensor(1.5829, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 875 tensor(1.5607, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 900 tensor(1.6210, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 925 tensor(1.7101, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 950 tensor(1.6058, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 975 tensor(2.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1000 tensor(3.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1025 tensor(2.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1050 tensor(1.9159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1075 tensor(1.7807, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1100 tensor(1.7114, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1125 tensor(2.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1150 tensor(1.7772, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1175 tensor(1.5966, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1200 tensor(1.5958, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1225 tensor(1.5724, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1250 tensor(1.5704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1275 tensor(1.5678, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1300 tensor(1.5926, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1325 tensor(1.5917, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1350 tensor(1.5893, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1375 tensor(156.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1400 tensor(286.2617, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1425 tensor(32.9315, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1450 tensor(19.5163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1475 tensor(15.9931, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1500 tensor(467.9088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1525 tensor(13.3476, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1550 tensor(149.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1575 tensor(205.5300, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1600 tensor(4.8413, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1625 tensor(1159.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1650 tensor(4.0658, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1675 tensor(517.9371, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1700 tensor(645.5909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1725 tensor(994.4617, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1750 tensor(5390.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "0 1775 tensor(2.4643, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 25 tensor(1.8957, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 50 tensor(2.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 75 tensor(2.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 100 tensor(26.9941, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 125 tensor(3.1549, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-636ee488ed9f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-f078c7322b31>\u001b[0m in \u001b[0;36mgetPrediction\u001b[0;34m(graph, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-eb658cef9b00>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m#print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gated_graph_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             m = self.propagate(edge_index, x=m, edge_weight=edge_weight,\n\u001b[0m\u001b[1;32m     80\u001b[0m                                size=None)\n\u001b[1;32m     81\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                         \u001b[0mmsg_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gated_graph_conv.py\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_j\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Datasets/bbc-full-text-document-classification/models/cheackpoints.pt'))"
      ],
      "metadata": {
        "id": "4IlJWTAyeT2X",
        "outputId": "ede1fa84-75a4-44d4-d574-99db8cea7bff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "165/222"
      ],
      "metadata": {
        "id": "ObRC8fimfAEX",
        "outputId": "34568d18-aaf7-4e58-8c2e-6e7e2f0568c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7432432432432432"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = 0\n",
        "for item in test_set:\n",
        "  item\n",
        "  model.to('cpu')\n",
        "  if np.argmax(getPrediction(item, model).detach().numpy()) == np.argmax(item.y.detach().numpy()):\n",
        "    c += 1\n",
        "\n",
        "print(f\"{c} from {len(test_set)}\")"
      ],
      "metadata": {
        "id": "HvrT_FO7c4E6",
        "outputId": "6669263e-a5a4-4080-fa43-26201f6a178f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "165 from 222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 165 from 222 for m1\n",
        "# 40 from 222\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "u9NYmQnJeLwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sqr(num):\n",
        "  return num**2\n",
        "sqr = np.vectorize(sqr)"
      ],
      "metadata": {
        "id": "f_x3T_Zz8UsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(10,)"
      ],
      "metadata": {
        "id": "Pv62fMhB8a3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(sqr(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DltFR8_R8knr",
        "outputId": "b32afdea-2e82-480a-d452-74aed7c274bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.2091, 0.2429, 2.7144, 0.1128, 0.2558, 0.0573, 0.2809, 0.4439, 1.9288,\n",
              "        0.9987], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9utNR4_v8mPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}